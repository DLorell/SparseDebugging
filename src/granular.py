import torch
import torch.nn as nn
import numpy as np

# TODO: Init dictionary atoms to be orthogonal and unit norm

class Sub_Dictionary(nn.Module):
    ###########################################################################
    # Single-Tier of a Hierarchical Dictionary for Neural Sparse Coding.
    #
    #   ch_in:                      Channel depth of input.
    #   ch_out:                     Channel depth of dense output.
    #   num_atoms:                  Number of atoms in this tier of the 
    #                               dictionary.
    #   k_div (optional):           Divisor of ch_out determining k. 
    #                               (e.g. k_div==2 and ch_out==32  =>  k==16)
    #   k (optional):               Explicit setting for k.
    #   kernel_size (optional):     Size of the kernels used as dictionary atoms.
    #
    #   Returns:
    #       z_i_sparse: Sparse portion of final descriptor code.
    #       mask_out:   1/0 Mask generated by TopK selection + input mask, to be used for gating next tier of sub-dictionary.     
    #
    #############################################################################
    def __init__(self, ch_in, ch_out, num_atoms, k_div=None, kernel_size=3, k=None):
        super().__init__()
        if k_div is None and k is None:
            raise Exception("One of k_div or k must not be None.")
        elif k_div is not None and k is not None:
            raise Exception("Undefined behavior when both k_div and k are specified. Pick one.")
        else:
            pass

        self.conv = nn.Conv2d(ch_in, num_atoms, kernel_size=kernel_size)
        self.k = np.maximum(1, ch_out//k_div) if k is None else k

        self.reducer = nn.Conv2d(num_atoms, ch_out, kernel_size=1)

    def forward(self, x, mask_in):
        # Ensure the input is a minibatch of images
        assert len(x.shape) == 4
        # Ensure the mask is the correct shape for the number of atoms in this sub-dictionary.
        assert mask_in.shape[1] == self.conv.weight.shape[0]

        # Correlation coefficient extraction
        alpha_prek = self.conv(x)
        # Consider only the subset of atomic correlations granted by the input mask.
        alpha_prek = alpha_prek * mask_in 

        # TopK masking
        _, indicies = torch.topk(torch.abs(alpha_prek), self.k, dim=1)
        mask_out = torch.zeros_like(alpha_prek).scatter_(1, indicies, 1).to(alpha_prek.device)
        z_i_sparse = alpha_prek * mask_out

        return z_i_sparse, mask_out

class HierarchicalEncodingDictionary(nn.Module):
    ###################################################
    #
    # An Hierarchical Encoding Dictionary ala Prof. Michael Maire.
    #
    #   Init:
    #       ch_in:              Channel depth of input data.
    #       ch_out:             Channel depth of dense output data.
    #       growth_factor:      Targeted factor with which to grow the number of atoms in successive tiers of the hierarchy.
    #       k_div:              Factor by which z_i is larger than the number of non-zeros of the tier, post TopK.
    #       tier_z_ratio:       Ratio of number-of-atoms to z_i size for all tiers.
    #       first_tier_size:    Number of atoms in the first tier.
    #
    #   Arguments for the forward pass:
    #       
    #       x:                  Input data.
    #       densify:            Boolean. Whether or not to apply the linear reduction operation and produce a dense code.
    #                           if False, then the output will not adhere to the desired ch_out argument.
    #
    #   Returns:
    #       
    #       out:                A sparse or dense code depending on the densify parameter.
    #       
    #
    ###################################################
    def __init__(self, ch_in, ch_out, growth_factor, k_div, tier_z_ratio, first_tier_size):
        super().__init__()

        z_portions = self.get_z_portions(first_tier_size, tier_z_ratio, ch_out, growth_factor)
        ks = [int(round(portion//k_div)) for portion in z_portions]
        sub_dicts = [Sub_Dictionary(ch_in=ch_in, ch_out=z_portions[0], num_atoms=first_tier_size, k=ks[0])] + \
                    [Sub_Dictionary(ch_in=ch_in, ch_out=z_portion, num_atoms=z_portion*tier_z_ratio, k=k) for z_portion, k in zip(z_portions[1:], ks[1:])]
        self.gate_maps = [torch.tensor([j%sub_dicts[i-1].conv.weight.shape[0] for j in range(sub_dicts[i].conv.weight.shape[0])]) for i in range(1, len(sub_dicts))] + [None]

        self.sub_dicts = nn.ModuleList(sub_dicts)
    
    def forward(self, x, densify):
        out = None
        mask = torch.ones((1, self.sub_dicts[0].conv.weight.shape[0], 1, 1)).to(x.device)
        for tier, gate_map in zip(self.sub_dicts, self.gate_maps):
            out_portion_sparse, mask = tier(x, mask)
            mask = mask[:, gate_map, :, :]
            out_portion = tier.reducer(out_portion_sparse) if densify else out_portion_sparse
            out = torch.cat((out, out_portion), dim=1) if out is not None else out_portion
        return out


    # Portions out the channels alloted by ch_out, based on tier growth rate.
    # Any remainder is added to the final portion, making the final tier grow by up to
    #   but not including the square of the growth rate.
    # Z portions are returned in ascending order.
    def get_z_portions(self, first_tier_size, tier_z_ratio, ch_out, growth_factor):
        z_portions = [first_tier_size // tier_z_ratio]
        cur_last_tier = first_tier_size
        while np.sum(z_portions) < ch_out:
            cur_last_tier = cur_last_tier * growth_factor
            z_portion = cur_last_tier // 2
            if z_portion + np.sum(z_portions) > ch_out:
                cur_last_tier = cur_last_tier//growth_factor
                remainder = ch_out - np.sum(z_portions)
                z_portions.append(remainder)
                break
            z_portions.append(z_portion)
        return sorted(z_portions)





